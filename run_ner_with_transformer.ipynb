{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_ner with transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMW7JKJW7+SREUgHm/Tl+Jz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c188a5422ee04bef87baf70fc11bfe75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3468c46eae24ea7a5aa060d6e0ffabe",
              "IPY_MODEL_45b06574e4d649ee9b3490f99400def4",
              "IPY_MODEL_06b6283836fe49379227da63d37f53a9"
            ],
            "layout": "IPY_MODEL_84abb0b5874e4a47a285d96378cd7543"
          }
        },
        "d3468c46eae24ea7a5aa060d6e0ffabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbe9349063f4123bdc5f4cad0c148cd",
            "placeholder": "​",
            "style": "IPY_MODEL_3307e31b36734168a429ec93080ed51e",
            "value": "Downloading builder script: "
          }
        },
        "45b06574e4d649ee9b3490f99400def4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07fb191e4bcc40369089d87a01b58e51",
            "max": 1697,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a6d49a7af2b4ef1ac28b43c0ed4f9c4",
            "value": 1697
          }
        },
        "06b6283836fe49379227da63d37f53a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7a17f6df024b98bcf6b975e21705f8",
            "placeholder": "​",
            "style": "IPY_MODEL_5c44cbdfad964c13be255adf7976f1cb",
            "value": " 5.25k/? [00:00&lt;00:00, 109kB/s]"
          }
        },
        "84abb0b5874e4a47a285d96378cd7543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dbe9349063f4123bdc5f4cad0c148cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3307e31b36734168a429ec93080ed51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07fb191e4bcc40369089d87a01b58e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6d49a7af2b4ef1ac28b43c0ed4f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e7a17f6df024b98bcf6b975e21705f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c44cbdfad964c13be255adf7976f1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd1f8a756e454b01bb7d914e4c03c647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d22d2f29f114f0ead2f0eec4c1b97e6",
              "IPY_MODEL_c37b9c30b56444e4b57ffec3ebeb4c03",
              "IPY_MODEL_363811ab64d74cce977a17d8ded746fb"
            ],
            "layout": "IPY_MODEL_2cc906b3d98c471d9d2be3298335b89d"
          }
        },
        "7d22d2f29f114f0ead2f0eec4c1b97e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ead80f08a5470985c9886f58164ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_af5992c9829848ef868c631d2a474d93",
            "value": "Downloading metadata: "
          }
        },
        "c37b9c30b56444e4b57ffec3ebeb4c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e547287d9f514b4c9cdd34015288442d",
            "max": 1043,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fa17aec31414616a18446478fb6acfa",
            "value": 1043
          }
        },
        "363811ab64d74cce977a17d8ded746fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f88d3da859a44faa77b1f71dd36908c",
            "placeholder": "​",
            "style": "IPY_MODEL_47acb15731a34726928f76af97e31c83",
            "value": " 2.65k/? [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "2cc906b3d98c471d9d2be3298335b89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ead80f08a5470985c9886f58164ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af5992c9829848ef868c631d2a474d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e547287d9f514b4c9cdd34015288442d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa17aec31414616a18446478fb6acfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f88d3da859a44faa77b1f71dd36908c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47acb15731a34726928f76af97e31c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff43e32c03fa4c8aa360c410ec6c25b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a578389f71934001b2689eba15abff9a",
              "IPY_MODEL_091b23f72ae043729387f64b0da05d26",
              "IPY_MODEL_3b663214f42045a98a0bcec0c2f23049"
            ],
            "layout": "IPY_MODEL_76ebe3649b7a49a2a71b03a3214a2b1b"
          }
        },
        "a578389f71934001b2689eba15abff9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad055a85bf5437387c975b5c973c312",
            "placeholder": "​",
            "style": "IPY_MODEL_4322bea0c940459297d0f622f4be8001",
            "value": "Downloading data: "
          }
        },
        "091b23f72ae043729387f64b0da05d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ec0644cd40c465aa03263c8668f6517",
            "max": 146802,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74ce5d7d77ff4ad9a6d2acbfa8d91048",
            "value": 146802
          }
        },
        "3b663214f42045a98a0bcec0c2f23049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff239ae18ba749ca83ff3781f92b204c",
            "placeholder": "​",
            "style": "IPY_MODEL_794218fb834845e1831369fb637a4691",
            "value": " 536k/? [00:00&lt;00:00, 6.62MB/s]"
          }
        },
        "76ebe3649b7a49a2a71b03a3214a2b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad055a85bf5437387c975b5c973c312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4322bea0c940459297d0f622f4be8001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ec0644cd40c465aa03263c8668f6517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ce5d7d77ff4ad9a6d2acbfa8d91048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff239ae18ba749ca83ff3781f92b204c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794218fb834845e1831369fb637a4691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e9bba9b7d0b4352839ab780f0030cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eec0e80a1439434dbef9dbfaa9528cb3",
              "IPY_MODEL_f4bbc960d31c4666a8a61b9e66c43a53",
              "IPY_MODEL_5b99830e6ba84fbcacc92bf90ab6e3d9"
            ],
            "layout": "IPY_MODEL_5fb70aaa05ba48b4ae0e21c98b832bb9"
          }
        },
        "eec0e80a1439434dbef9dbfaa9528cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327d68c96c6e407597e9f350411809a1",
            "placeholder": "​",
            "style": "IPY_MODEL_832b51f8b6de43599e4096df8b85da7d",
            "value": "Downloading data: "
          }
        },
        "f4bbc960d31c4666a8a61b9e66c43a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc14ec2f80a47aeb26c85fc813c5aea",
            "max": 30125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6595a8b448c4cd18f61a076c94ddb9b",
            "value": 30125
          }
        },
        "5b99830e6ba84fbcacc92bf90ab6e3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ddc1f852314041ab14c9fa16404d4c",
            "placeholder": "​",
            "style": "IPY_MODEL_fc568f8d58674947966fa6513325971a",
            "value": " 106k/? [00:00&lt;00:00, 2.35MB/s]"
          }
        },
        "5fb70aaa05ba48b4ae0e21c98b832bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "327d68c96c6e407597e9f350411809a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832b51f8b6de43599e4096df8b85da7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc14ec2f80a47aeb26c85fc813c5aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6595a8b448c4cd18f61a076c94ddb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12ddc1f852314041ab14c9fa16404d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc568f8d58674947966fa6513325971a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9af70863bdc4474392476d33ec8d4a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_281e732ac1ee462a85d40c2e29cf8700",
              "IPY_MODEL_1e1786c7ee89482d8f205acb3f4d49f9",
              "IPY_MODEL_e86bacd0d4914096a80c5f3ad32ca8b1"
            ],
            "layout": "IPY_MODEL_ba6168a0acb2481c92e5797aa6169fe1"
          }
        },
        "281e732ac1ee462a85d40c2e29cf8700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_816603808f9346829dac15e260db965f",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6784b8a4184cb885807e64e0009213",
            "value": "Downloading data: "
          }
        },
        "1e1786c7ee89482d8f205acb3f4d49f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e44e75d463574c69bc5935e0a94124f8",
            "max": 31026,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ef1595b5984479c83641112992bf357",
            "value": 31026
          }
        },
        "e86bacd0d4914096a80c5f3ad32ca8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3634c14d25b146a6af84998b1b467354",
            "placeholder": "​",
            "style": "IPY_MODEL_143f5a7d918c4f0b9c54100907492c57",
            "value": " 109k/? [00:00&lt;00:00, 2.59MB/s]"
          }
        },
        "ba6168a0acb2481c92e5797aa6169fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816603808f9346829dac15e260db965f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6784b8a4184cb885807e64e0009213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e44e75d463574c69bc5935e0a94124f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef1595b5984479c83641112992bf357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3634c14d25b146a6af84998b1b467354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143f5a7d918c4f0b9c54100907492c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b2b517321604c30a71d3a868e87149f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b363759983f74558be7fe478477ef79c",
              "IPY_MODEL_9dfa9655ea3d43ed84985a8daa839fbc",
              "IPY_MODEL_743547d3916049a59ae122bf9a8c5e38"
            ],
            "layout": "IPY_MODEL_26ea9909a53f4ee98ec212839270fe1b"
          }
        },
        "b363759983f74558be7fe478477ef79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c5d0d63ffe4660b6ea8bdb25a09c35",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcdc7903162474d85868a89b8754027",
            "value": "Generating train split:  96%"
          }
        },
        "9dfa9655ea3d43ed84985a8daa839fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_437d207a952844f5aae84efbfaeff351",
            "max": 1350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_768b6b5829184ffba96bbccb92c93a5a",
            "value": 1350
          }
        },
        "743547d3916049a59ae122bf9a8c5e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7977fa16059b4269b5871fc22dd73562",
            "placeholder": "​",
            "style": "IPY_MODEL_8a2f8e9995da4c828ef6a80facf6377d",
            "value": " 1292/1350 [00:00&lt;00:00, 2001.59 examples/s]"
          }
        },
        "26ea9909a53f4ee98ec212839270fe1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c5d0d63ffe4660b6ea8bdb25a09c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcdc7903162474d85868a89b8754027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "437d207a952844f5aae84efbfaeff351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768b6b5829184ffba96bbccb92c93a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7977fa16059b4269b5871fc22dd73562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2f8e9995da4c828ef6a80facf6377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18848d035542447e924e9f7668d7321c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e725a0ee9550426f96da0670bc7550f8",
              "IPY_MODEL_d1e00cbf968e43fb9e30230fd50c5c9e",
              "IPY_MODEL_7905457bdda140639304533bf5b3ad45"
            ],
            "layout": "IPY_MODEL_a930604875c740ab94ca0d952d7ebfe8"
          }
        },
        "e725a0ee9550426f96da0670bc7550f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1aeabf97e94abd8b4b826a9d6edb6b",
            "placeholder": "​",
            "style": "IPY_MODEL_b6db3f7fa2bc4f18a1c253d7adb89ed0",
            "value": "Generating validation split:  57%"
          }
        },
        "d1e00cbf968e43fb9e30230fd50c5c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b534f3aa3d6454fbc4cfadb34bbdba8",
            "max": 270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1912a3363f1745a8ac27b9f5e17943b0",
            "value": 270
          }
        },
        "7905457bdda140639304533bf5b3ad45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682d2d491cd248a980eeb8300d0f2ecc",
            "placeholder": "​",
            "style": "IPY_MODEL_34fc77fe23e34f1fbabb77afabc5caf4",
            "value": " 154/270 [00:00&lt;00:00, 453.73 examples/s]"
          }
        },
        "a930604875c740ab94ca0d952d7ebfe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1aeabf97e94abd8b4b826a9d6edb6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6db3f7fa2bc4f18a1c253d7adb89ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b534f3aa3d6454fbc4cfadb34bbdba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1912a3363f1745a8ac27b9f5e17943b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "682d2d491cd248a980eeb8300d0f2ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fc77fe23e34f1fbabb77afabc5caf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aacc80c866bd4fa88a5bf57a27b97bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db65f64fc034ee5846306b5832564a6",
              "IPY_MODEL_49ad12e5ce784196a920ea2d01049e05",
              "IPY_MODEL_3a92d63216ee49e2b0f7f846fc372a72"
            ],
            "layout": "IPY_MODEL_f6572fc9ff504d4ca374531d9529c0ec"
          }
        },
        "2db65f64fc034ee5846306b5832564a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f490e800194f32ad793315e68ec178",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0652d4b0dc4d01b9bcc7e0bfda0c85",
            "value": "Generating test split:  82%"
          }
        },
        "49ad12e5ce784196a920ea2d01049e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9aa830aa9e1474f91e4850b2972b45e",
            "max": 270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_798ca87399164c81a39491454ae233a4",
            "value": 270
          }
        },
        "3a92d63216ee49e2b0f7f846fc372a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c819931fde4339a6f6233c2c739514",
            "placeholder": "​",
            "style": "IPY_MODEL_7db9dab71e1f490abcf72cffa98b2cab",
            "value": " 222/270 [00:00&lt;00:00, 1184.25 examples/s]"
          }
        },
        "f6572fc9ff504d4ca374531d9529c0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f490e800194f32ad793315e68ec178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0652d4b0dc4d01b9bcc7e0bfda0c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9aa830aa9e1474f91e4850b2972b45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798ca87399164c81a39491454ae233a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c819931fde4339a6f6233c2c739514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db9dab71e1f490abcf72cffa98b2cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d145df2cb6144e369477e8ecd563bc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d5a33fb4394ee681d9b45d083eadbd",
              "IPY_MODEL_89d604a678cc43f999fad9d48ae21b35",
              "IPY_MODEL_ef29d17b82da4d0ea9a8425759e5bef6"
            ],
            "layout": "IPY_MODEL_201a69509cbf4a74b26cffa5ce25faf1"
          }
        },
        "11d5a33fb4394ee681d9b45d083eadbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891f19d98c63470598713e87cf20b27a",
            "placeholder": "​",
            "style": "IPY_MODEL_0fbf3e1615db49d180ed6c0e14543b3a",
            "value": "100%"
          }
        },
        "89d604a678cc43f999fad9d48ae21b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc803867202409d98f9fa73461f77af",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19bc4bc9c6b24bdf914f2b90c09cd3b4",
            "value": 3
          }
        },
        "ef29d17b82da4d0ea9a8425759e5bef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bbf1cbf5e6b4fc9827ce31d453d0e67",
            "placeholder": "​",
            "style": "IPY_MODEL_811e0615745e4dd49fbeb9c85866da58",
            "value": " 3/3 [00:00&lt;00:00, 42.21it/s]"
          }
        },
        "201a69509cbf4a74b26cffa5ce25faf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891f19d98c63470598713e87cf20b27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbf3e1615db49d180ed6c0e14543b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dc803867202409d98f9fa73461f77af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19bc4bc9c6b24bdf914f2b90c09cd3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bbf1cbf5e6b4fc9827ce31d453d0e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811e0615745e4dd49fbeb9c85866da58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/NER/blob/main/run_ner_with_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1_V4kMUEGcW",
        "outputId": "554dbece-5c8a-4bde-ef63-042b6644a6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Using cached datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 21.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Using cached fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting xxhash\n",
            "  Using cached xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "Collecting responses<0.19\n",
            "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0691d383b7b2c309f19d23137810f5a88d3eb313122a433f369e364873d2e285\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGgqxkJXEYBN",
        "outputId": "c79dff9d-f435-4b67-c6df-23c4abe4e471"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 93416, done.\u001b[K\n",
            "remote: Total 93416 (delta 0), reused 0 (delta 0), pack-reused 93416\u001b[K\n",
            "Receiving objects: 100% (93416/93416), 85.71 MiB | 12.17 MiB/s, done.\n",
            "Resolving deltas: 100% (68511/68511), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAhLvttmFhob",
        "outputId": "c58fe067-bee2-4a48-e585-7cd36bc0e849"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/transformers/examples/pytorch/token-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNjSsp14El0j",
        "outputId": "970b2014-cd25-48ec-c487-c3e1a9bfe49d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers/examples/pytorch/token-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data=load_dataset('weibo_ner')\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "c188a5422ee04bef87baf70fc11bfe75",
            "d3468c46eae24ea7a5aa060d6e0ffabe",
            "45b06574e4d649ee9b3490f99400def4",
            "06b6283836fe49379227da63d37f53a9",
            "84abb0b5874e4a47a285d96378cd7543",
            "2dbe9349063f4123bdc5f4cad0c148cd",
            "3307e31b36734168a429ec93080ed51e",
            "07fb191e4bcc40369089d87a01b58e51",
            "8a6d49a7af2b4ef1ac28b43c0ed4f9c4",
            "3e7a17f6df024b98bcf6b975e21705f8",
            "5c44cbdfad964c13be255adf7976f1cb",
            "dd1f8a756e454b01bb7d914e4c03c647",
            "7d22d2f29f114f0ead2f0eec4c1b97e6",
            "c37b9c30b56444e4b57ffec3ebeb4c03",
            "363811ab64d74cce977a17d8ded746fb",
            "2cc906b3d98c471d9d2be3298335b89d",
            "45ead80f08a5470985c9886f58164ba9",
            "af5992c9829848ef868c631d2a474d93",
            "e547287d9f514b4c9cdd34015288442d",
            "4fa17aec31414616a18446478fb6acfa",
            "9f88d3da859a44faa77b1f71dd36908c",
            "47acb15731a34726928f76af97e31c83",
            "ff43e32c03fa4c8aa360c410ec6c25b3",
            "a578389f71934001b2689eba15abff9a",
            "091b23f72ae043729387f64b0da05d26",
            "3b663214f42045a98a0bcec0c2f23049",
            "76ebe3649b7a49a2a71b03a3214a2b1b",
            "5ad055a85bf5437387c975b5c973c312",
            "4322bea0c940459297d0f622f4be8001",
            "7ec0644cd40c465aa03263c8668f6517",
            "74ce5d7d77ff4ad9a6d2acbfa8d91048",
            "ff239ae18ba749ca83ff3781f92b204c",
            "794218fb834845e1831369fb637a4691",
            "2e9bba9b7d0b4352839ab780f0030cdc",
            "eec0e80a1439434dbef9dbfaa9528cb3",
            "f4bbc960d31c4666a8a61b9e66c43a53",
            "5b99830e6ba84fbcacc92bf90ab6e3d9",
            "5fb70aaa05ba48b4ae0e21c98b832bb9",
            "327d68c96c6e407597e9f350411809a1",
            "832b51f8b6de43599e4096df8b85da7d",
            "efc14ec2f80a47aeb26c85fc813c5aea",
            "e6595a8b448c4cd18f61a076c94ddb9b",
            "12ddc1f852314041ab14c9fa16404d4c",
            "fc568f8d58674947966fa6513325971a",
            "9af70863bdc4474392476d33ec8d4a41",
            "281e732ac1ee462a85d40c2e29cf8700",
            "1e1786c7ee89482d8f205acb3f4d49f9",
            "e86bacd0d4914096a80c5f3ad32ca8b1",
            "ba6168a0acb2481c92e5797aa6169fe1",
            "816603808f9346829dac15e260db965f",
            "ec6784b8a4184cb885807e64e0009213",
            "e44e75d463574c69bc5935e0a94124f8",
            "3ef1595b5984479c83641112992bf357",
            "3634c14d25b146a6af84998b1b467354",
            "143f5a7d918c4f0b9c54100907492c57",
            "3b2b517321604c30a71d3a868e87149f",
            "b363759983f74558be7fe478477ef79c",
            "9dfa9655ea3d43ed84985a8daa839fbc",
            "743547d3916049a59ae122bf9a8c5e38",
            "26ea9909a53f4ee98ec212839270fe1b",
            "c0c5d0d63ffe4660b6ea8bdb25a09c35",
            "2bcdc7903162474d85868a89b8754027",
            "437d207a952844f5aae84efbfaeff351",
            "768b6b5829184ffba96bbccb92c93a5a",
            "7977fa16059b4269b5871fc22dd73562",
            "8a2f8e9995da4c828ef6a80facf6377d",
            "18848d035542447e924e9f7668d7321c",
            "e725a0ee9550426f96da0670bc7550f8",
            "d1e00cbf968e43fb9e30230fd50c5c9e",
            "7905457bdda140639304533bf5b3ad45",
            "a930604875c740ab94ca0d952d7ebfe8",
            "ec1aeabf97e94abd8b4b826a9d6edb6b",
            "b6db3f7fa2bc4f18a1c253d7adb89ed0",
            "0b534f3aa3d6454fbc4cfadb34bbdba8",
            "1912a3363f1745a8ac27b9f5e17943b0",
            "682d2d491cd248a980eeb8300d0f2ecc",
            "34fc77fe23e34f1fbabb77afabc5caf4",
            "aacc80c866bd4fa88a5bf57a27b97bc9",
            "2db65f64fc034ee5846306b5832564a6",
            "49ad12e5ce784196a920ea2d01049e05",
            "3a92d63216ee49e2b0f7f846fc372a72",
            "f6572fc9ff504d4ca374531d9529c0ec",
            "a2f490e800194f32ad793315e68ec178",
            "ac0652d4b0dc4d01b9bcc7e0bfda0c85",
            "c9aa830aa9e1474f91e4850b2972b45e",
            "798ca87399164c81a39491454ae233a4",
            "07c819931fde4339a6f6233c2c739514",
            "7db9dab71e1f490abcf72cffa98b2cab",
            "d145df2cb6144e369477e8ecd563bc0a",
            "11d5a33fb4394ee681d9b45d083eadbd",
            "89d604a678cc43f999fad9d48ae21b35",
            "ef29d17b82da4d0ea9a8425759e5bef6",
            "201a69509cbf4a74b26cffa5ce25faf1",
            "891f19d98c63470598713e87cf20b27a",
            "0fbf3e1615db49d180ed6c0e14543b3a",
            "3dc803867202409d98f9fa73461f77af",
            "19bc4bc9c6b24bdf914f2b90c09cd3b4",
            "9bbf1cbf5e6b4fc9827ce31d453d0e67",
            "811e0615745e4dd49fbeb9c85866da58"
          ]
        },
        "id": "rIGn7c9uUMzM",
        "outputId": "beab25eb-4f21-4459-f512-0194ccf7f1fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.70k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c188a5422ee04bef87baf70fc11bfe75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd1f8a756e454b01bb7d914e4c03c647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset weibo_ner_corpus/default (download: 733.09 KiB, generated: 1.57 MiB, post-processed: Unknown size, total: 2.29 MiB) to /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/147k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff43e32c03fa4c8aa360c410ec6c25b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/30.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e9bba9b7d0b4352839ab780f0030cdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/31.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9af70863bdc4474392476d33ec8d4a41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1350 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b2b517321604c30a71d3a868e87149f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/270 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18848d035542447e924e9f7668d7321c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/270 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aacc80c866bd4fa88a5bf57a27b97bc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset weibo_ner_corpus downloaded and prepared to /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d145df2cb6144e369477e8ecd563bc0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 1350\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 270\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 270\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NSsy25xsUXPd",
        "outputId": "6ede6d3e-29f3-4526-b026-21e16e96e650"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train=pd.DataFrame(data['train'])\n",
        "df_train=df_train.drop(columns=['id'])\n",
        "\n",
        "df_valid=pd.DataFrame(data['validation'])\n",
        "df_valid=df_valid.drop(columns=['id'])\n",
        "\n",
        "df_test=pd.DataFrame(data['test'])\n",
        "df_test=df_test.drop(columns=['id'])\n",
        "\n",
        "df_train.to_csv('train.csv',index=False)\n",
        "df_valid.to_csv('valid.csv',index=False)\n",
        "df_test.to_csv('test.csv',index=False)"
      ],
      "metadata": {
        "id": "mn2CjeGIozkY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path bert-base-chinese \\\n",
        "  --dataset_name weibo_ner \\\n",
        "  --output_dir /content/bert-base-out \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --fp16 \\\n",
        "  --do_eval \\\n",
        "  --save_strategy epoch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk3hfRAQTNGZ",
        "outputId": "8f1624aa-7c8b-4796-ba33-ebc4f985e8d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 12:27:31 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/06/2022 12:27:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/bert-base-out/runs/May06_12-27-31_edd37792f991,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=2.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/bert-base-out,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/bert-base-out,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 12:27:32 - WARNING - datasets.builder - Using custom data configuration default\n",
            "05/06/2022 12:27:32 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/weibo_ner/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:27:32 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/06/2022 12:27:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:27:32 - WARNING - datasets.builder - Reusing dataset weibo_ner_corpus (/root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a)\n",
            "05/06/2022 12:27:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "100% 3/3 [00:00<00:00, 696.54it/s]\n",
            "[INFO|hub.py:583] 2022-05-06 12:27:33,681 >> https://huggingface.co/bert-base-chinese/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppk3_cme3\n",
            "Downloading: 100% 624/624 [00:00<00:00, 539kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:27:34,436 >> storing https://huggingface.co/bert-base-chinese/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
            "[INFO|hub.py:595] 2022-05-06 12:27:34,436 >> creating metadata file for /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:27:34,436 >> loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:27:34,438 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-chinese\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:27:35,198 >> https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpklq0lgkd\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 25.3kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:27:35,969 >> storing https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|hub.py:595] 2022-05-06 12:27:35,969 >> creating metadata file for /root/.cache/huggingface/transformers/2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:27:36,731 >> loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:27:36,732 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-chinese\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:27:38,251 >> https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwultc0h3\n",
            "Downloading: 100% 107k/107k [00:00<00:00, 199kB/s] \n",
            "[INFO|hub.py:587] 2022-05-06 12:27:39,563 >> storing https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:595] 2022-05-06 12:27:39,563 >> creating metadata file for /root/.cache/huggingface/transformers/36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:583] 2022-05-06 12:27:40,311 >> https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps1l1u9c1\n",
            "Downloading: 100% 263k/263k [00:00<00:00, 366kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:27:41,812 >> storing https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
            "[INFO|hub.py:595] 2022-05-06 12:27:41,812 >> creating metadata file for /root/.cache/huggingface/transformers/7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:27:44,094 >> loading file https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:27:44,095 >> loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/7e23f4e1f58f867d672f84d9a459826e41cea3be6d0fe62502ddce9920f57e48.4495f7812b44ff0568ce7c4ff3fdbb2bac5eaf330440ffa30f46893bf749184d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:27:44,095 >> loading file https://huggingface.co/bert-base-chinese/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:27:44,095 >> loading file https://huggingface.co/bert-base-chinese/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:27:44,095 >> loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:27:44,854 >> loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:27:44,854 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-chinese\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:27:45,652 >> https://huggingface.co/bert-base-chinese/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptzbto4da\n",
            "Downloading: 100% 393M/393M [00:09<00:00, 41.9MB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:27:55,560 >> storing https://huggingface.co/bert-base-chinese/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/58592490276d9ed1e8e33f3c12caf23000c22973cb2b3218c641bd74547a1889.fabda197bfe5d6a318c2833172d6757ccc7e49f692cb949a6fabf560cee81508\n",
            "[INFO|hub.py:595] 2022-05-06 12:27:55,560 >> creating metadata file for /root/.cache/huggingface/transformers/58592490276d9ed1e8e33f3c12caf23000c22973cb2b3218c641bd74547a1889.fabda197bfe5d6a318c2833172d6757ccc7e49f692cb949a6fabf560cee81508\n",
            "[INFO|modeling_utils.py:1772] 2022-05-06 12:27:55,560 >> loading weights file https://huggingface.co/bert-base-chinese/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/58592490276d9ed1e8e33f3c12caf23000c22973cb2b3218c641bd74547a1889.fabda197bfe5d6a318c2833172d6757ccc7e49f692cb949a6fabf560cee81508\n",
            "[WARNING|modeling_utils.py:2049] 2022-05-06 12:27:57,345 >> Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2060] 2022-05-06 12:27:57,345 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on train dataset:   0% 0/2 [00:00<?, ?ba/s]05/06/2022 12:27:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-5181f344266aae21.arrow\n",
            "Running tokenizer on train dataset: 100% 2/2 [00:00<00:00,  2.83ba/s]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]05/06/2022 12:27:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-1ec414628feac464.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  8.65ba/s]\n",
            "05/06/2022 12:27:59 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.1.0/metrics/seqeval/seqeval.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpmrchib56\n",
            "Downloading builder script: 6.33kB [00:00, 6.59MB/s]       \n",
            "05/06/2022 12:27:59 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.1.0/metrics/seqeval/seqeval.py in cache at /root/.cache/huggingface/datasets/downloads/a5315e76e3c39bffd2973239633276d8750ff0894f5bf6f8a1c874492b261d59.63490f48f0656d09ada2c86daed79587694915df82dd311e407b049ad2f525eb.py\n",
            "05/06/2022 12:27:59 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/a5315e76e3c39bffd2973239633276d8750ff0894f5bf6f8a1c874492b261d59.63490f48f0656d09ada2c86daed79587694915df82dd311e407b049ad2f525eb.py\n",
            "[INFO|trainer.py:453] 2022-05-06 12:28:10,038 >> Using amp half precision backend\n",
            "[INFO|trainer.py:567] 2022-05-06 12:28:10,039 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1290] 2022-05-06 12:28:10,052 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2022-05-06 12:28:10,052 >>   Num examples = 1350\n",
            "[INFO|trainer.py:1292] 2022-05-06 12:28:10,052 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:1293] 2022-05-06 12:28:10,052 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2022-05-06 12:28:10,052 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2022-05-06 12:28:10,052 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2022-05-06 12:28:10,052 >>   Total optimization steps = 170\n",
            " 50% 85/170 [03:44<03:02,  2.15s/it][INFO|trainer.py:2166] 2022-05-06 12:31:54,181 >> Saving model checkpoint to /content/bert-base-out/checkpoint-85\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:31:54,182 >> Configuration saved in /content/bert-base-out/checkpoint-85/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:31:55,328 >> Model weights saved in /content/bert-base-out/checkpoint-85/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:31:55,329 >> tokenizer config file saved in /content/bert-base-out/checkpoint-85/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:31:55,329 >> Special tokens file saved in /content/bert-base-out/checkpoint-85/special_tokens_map.json\n",
            "100% 170/170 [07:31<00:00,  2.25s/it][INFO|trainer.py:2166] 2022-05-06 12:35:41,808 >> Saving model checkpoint to /content/bert-base-out/checkpoint-170\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:35:41,809 >> Configuration saved in /content/bert-base-out/checkpoint-170/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:35:42,855 >> Model weights saved in /content/bert-base-out/checkpoint-170/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:35:42,856 >> tokenizer config file saved in /content/bert-base-out/checkpoint-170/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:35:42,856 >> Special tokens file saved in /content/bert-base-out/checkpoint-170/special_tokens_map.json\n",
            "[INFO|trainer.py:1530] 2022-05-06 12:35:45,874 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 455.822, 'train_samples_per_second': 5.923, 'train_steps_per_second': 0.373, 'train_loss': 0.2904803556554458, 'epoch': 2.0}\n",
            "100% 170/170 [07:35<00:00,  2.68s/it]\n",
            "[INFO|trainer.py:2166] 2022-05-06 12:35:45,876 >> Saving model checkpoint to /content/bert-base-out\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:35:45,877 >> Configuration saved in /content/bert-base-out/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:35:47,555 >> Model weights saved in /content/bert-base-out/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:35:47,555 >> tokenizer config file saved in /content/bert-base-out/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:35:47,555 >> Special tokens file saved in /content/bert-base-out/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  train_loss               =     0.2905\n",
            "  train_runtime            = 0:07:35.82\n",
            "  train_samples            =       1350\n",
            "  train_samples_per_second =      5.923\n",
            "  train_steps_per_second   =      0.373\n",
            "05/06/2022 12:35:47 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:567] 2022-05-06 12:35:47,584 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2022-05-06 12:35:47,586 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2022-05-06 12:35:47,586 >>   Num examples = 270\n",
            "[INFO|trainer.py:2421] 2022-05-06 12:35:47,586 >>   Batch size = 8\n",
            "100% 34/34 [00:13<00:00,  2.50it/s]/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/06/2022 12:36:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 34/34 [00:13<00:00,  2.51it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =     0.9671\n",
            "  eval_f1                 =     0.5772\n",
            "  eval_loss               =     0.1119\n",
            "  eval_precision          =     0.5109\n",
            "  eval_recall             =     0.6632\n",
            "  eval_runtime            = 0:00:13.95\n",
            "  eval_samples            =        270\n",
            "  eval_samples_per_second =     19.346\n",
            "  eval_steps_per_second   =      2.436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bert-base-chinese 2轮F1为0.57"
      ],
      "metadata": {
        "id": "Zp5xfuYUYsPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path hfl/chinese-bert-wwm-ext \\\n",
        "  --dataset_name weibo_ner \\\n",
        "  --output_dir /content/bert \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --fp16 \\\n",
        "  --do_eval \\\n",
        "  --save_strategy epoch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGsA3C-7Y23N",
        "outputId": "493ba042-a1d4-48ac-85fb-58334b3553e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 12:42:34 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/06/2022 12:42:34 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/bert/runs/May06_12-42-34_edd37792f991,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=2.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/bert,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/bert,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 12:42:36 - WARNING - datasets.builder - Using custom data configuration default\n",
            "05/06/2022 12:42:36 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/weibo_ner/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:42:36 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/06/2022 12:42:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:42:36 - WARNING - datasets.builder - Reusing dataset weibo_ner_corpus (/root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a)\n",
            "05/06/2022 12:42:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "100% 3/3 [00:00<00:00, 632.88it/s]\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:36,932 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwb0z_t7z\n",
            "Downloading: 100% 647/647 [00:00<00:00, 428kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:42:37,695 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/f743bf42a15edcec990083d00483a90755ba0cf710582fd8ea7d4f62dae37930.ed1cdde95c19c04b6958803377b47e5f530c3b92ff1a32a9a4712beee0ffbe60\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:37,696 >> creating metadata file for /root/.cache/huggingface/transformers/f743bf42a15edcec990083d00483a90755ba0cf710582fd8ea7d4f62dae37930.ed1cdde95c19c04b6958803377b47e5f530c3b92ff1a32a9a4712beee0ffbe60\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:42:37,696 >> loading configuration file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f743bf42a15edcec990083d00483a90755ba0cf710582fd8ea7d4f62dae37930.ed1cdde95c19c04b6958803377b47e5f530c3b92ff1a32a9a4712beee0ffbe60\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:42:37,700 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-bert-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:38,462 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7_lj4ry7\n",
            "Downloading: 100% 19.0/19.0 [00:00<00:00, 13.7kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:42:39,224 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/a2da8b1b8d3e80c69ca848ca47191f158dfcd79bf8755ea3d367ee0740ee5bf7.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:39,224 >> creating metadata file for /root/.cache/huggingface/transformers/a2da8b1b8d3e80c69ca848ca47191f158dfcd79bf8755ea3d367ee0740ee5bf7.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:42:39,986 >> loading configuration file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f743bf42a15edcec990083d00483a90755ba0cf710582fd8ea7d4f62dae37930.ed1cdde95c19c04b6958803377b47e5f530c3b92ff1a32a9a4712beee0ffbe60\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:42:39,986 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-bert-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:41,485 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpf4a5e24u\n",
            "Downloading: 100% 107k/107k [00:00<00:00, 202kB/s] \n",
            "[INFO|hub.py:587] 2022-05-06 12:42:42,778 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/e3021c5be1377ed2fae9cbb707ed63c2d55cd36defe56073405a838400e522a2.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:42,778 >> creating metadata file for /root/.cache/huggingface/transformers/e3021c5be1377ed2fae9cbb707ed63c2d55cd36defe56073405a838400e522a2.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:43,536 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe3bo_yvi\n",
            "Downloading: 100% 263k/263k [00:00<00:00, 372kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:42:45,015 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/d64182facc334e1261387c7722a309f06ceef4d5f5cd1e2a36250e962a9ecd6b.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:45,015 >> creating metadata file for /root/.cache/huggingface/transformers/d64182facc334e1261387c7722a309f06ceef4d5f5cd1e2a36250e962a9ecd6b.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:45,777 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpbrmdq7t9\n",
            "Downloading: 100% 2.00/2.00 [00:00<00:00, 1.71kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:42:46,539 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/06877544701df259a4f8491d3cc5376857042cebf9f7a88e728d292f0b59eacc.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:46,540 >> creating metadata file for /root/.cache/huggingface/transformers/06877544701df259a4f8491d3cc5376857042cebf9f7a88e728d292f0b59eacc.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:47,292 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnbuwev1a\n",
            "Downloading: 100% 112/112 [00:00<00:00, 88.1kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:42:48,043 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/8183382ed1d3dbb68e827ee934b131f7a2fded38f6b5d6e94cf29c9e363e7cde.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|hub.py:595] 2022-05-06 12:42:48,043 >> creating metadata file for /root/.cache/huggingface/transformers/8183382ed1d3dbb68e827ee934b131f7a2fded38f6b5d6e94cf29c9e363e7cde.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:42:48,801 >> loading file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/e3021c5be1377ed2fae9cbb707ed63c2d55cd36defe56073405a838400e522a2.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:42:48,801 >> loading file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d64182facc334e1261387c7722a309f06ceef4d5f5cd1e2a36250e962a9ecd6b.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:42:48,801 >> loading file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/06877544701df259a4f8491d3cc5376857042cebf9f7a88e728d292f0b59eacc.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:42:48,801 >> loading file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/8183382ed1d3dbb68e827ee934b131f7a2fded38f6b5d6e94cf29c9e363e7cde.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:42:48,801 >> loading file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a2da8b1b8d3e80c69ca848ca47191f158dfcd79bf8755ea3d367ee0740ee5bf7.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:42:49,548 >> loading configuration file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f743bf42a15edcec990083d00483a90755ba0cf710582fd8ea7d4f62dae37930.ed1cdde95c19c04b6958803377b47e5f530c3b92ff1a32a9a4712beee0ffbe60\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:42:49,549 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-bert-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 12:42:50,407 >> https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpif6p9tq0\n",
            "Downloading: 100% 393M/393M [00:10<00:00, 38.7MB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 12:43:02,146 >> storing https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/e0ae57abc5d60c251881d3a8bebcbec955fdc4ba41f7b6008907c2eaf91b6a0f.7a9ca34f4c2480b431d6e5f9a4e27a6baf8e8f54ec3f4981edf4a9772ca2fffc\n",
            "[INFO|hub.py:595] 2022-05-06 12:43:02,147 >> creating metadata file for /root/.cache/huggingface/transformers/e0ae57abc5d60c251881d3a8bebcbec955fdc4ba41f7b6008907c2eaf91b6a0f.7a9ca34f4c2480b431d6e5f9a4e27a6baf8e8f54ec3f4981edf4a9772ca2fffc\n",
            "[INFO|modeling_utils.py:1772] 2022-05-06 12:43:02,147 >> loading weights file https://huggingface.co/hfl/chinese-bert-wwm-ext/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/e0ae57abc5d60c251881d3a8bebcbec955fdc4ba41f7b6008907c2eaf91b6a0f.7a9ca34f4c2480b431d6e5f9a4e27a6baf8e8f54ec3f4981edf4a9772ca2fffc\n",
            "[WARNING|modeling_utils.py:2049] 2022-05-06 12:43:03,907 >> Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2060] 2022-05-06 12:43:03,907 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on train dataset:   0% 0/2 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:2340] 2022-05-06 12:43:04,043 >> Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "05/06/2022 12:43:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-eb1eca18ee516df6.arrow\n",
            "Running tokenizer on train dataset: 100% 2/2 [00:00<00:00,  2.86ba/s]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]05/06/2022 12:43:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-0c7acff53d6c27fb.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  7.60ba/s]\n",
            "[INFO|trainer.py:453] 2022-05-06 12:43:08,764 >> Using amp half precision backend\n",
            "[INFO|trainer.py:567] 2022-05-06 12:43:08,765 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1290] 2022-05-06 12:43:08,778 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2022-05-06 12:43:08,778 >>   Num examples = 1350\n",
            "[INFO|trainer.py:1292] 2022-05-06 12:43:08,779 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:1293] 2022-05-06 12:43:08,779 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2022-05-06 12:43:08,779 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2022-05-06 12:43:08,779 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2022-05-06 12:43:08,779 >>   Total optimization steps = 170\n",
            " 50% 85/170 [03:45<03:02,  2.14s/it][INFO|trainer.py:2166] 2022-05-06 12:46:54,650 >> Saving model checkpoint to /content/bert/checkpoint-85\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:46:54,651 >> Configuration saved in /content/bert/checkpoint-85/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:46:55,684 >> Model weights saved in /content/bert/checkpoint-85/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:46:55,685 >> tokenizer config file saved in /content/bert/checkpoint-85/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:46:55,685 >> Special tokens file saved in /content/bert/checkpoint-85/special_tokens_map.json\n",
            "100% 170/170 [07:34<00:00,  2.29s/it][INFO|trainer.py:2166] 2022-05-06 12:50:43,587 >> Saving model checkpoint to /content/bert/checkpoint-170\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:50:43,588 >> Configuration saved in /content/bert/checkpoint-170/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:50:44,635 >> Model weights saved in /content/bert/checkpoint-170/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:50:44,636 >> tokenizer config file saved in /content/bert/checkpoint-170/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:50:44,636 >> Special tokens file saved in /content/bert/checkpoint-170/special_tokens_map.json\n",
            "[INFO|trainer.py:1530] 2022-05-06 12:50:47,700 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 458.9214, 'train_samples_per_second': 5.883, 'train_steps_per_second': 0.37, 'train_loss': 0.2937881245332606, 'epoch': 2.0}\n",
            "100% 170/170 [07:38<00:00,  2.70s/it]\n",
            "[INFO|trainer.py:2166] 2022-05-06 12:50:47,703 >> Saving model checkpoint to /content/bert\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 12:50:47,705 >> Configuration saved in /content/bert/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 12:50:49,288 >> Model weights saved in /content/bert/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 12:50:49,289 >> tokenizer config file saved in /content/bert/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 12:50:49,289 >> Special tokens file saved in /content/bert/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  train_loss               =     0.2938\n",
            "  train_runtime            = 0:07:38.92\n",
            "  train_samples            =       1350\n",
            "  train_samples_per_second =      5.883\n",
            "  train_steps_per_second   =       0.37\n",
            "05/06/2022 12:50:49 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:567] 2022-05-06 12:50:49,316 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2022-05-06 12:50:49,319 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2022-05-06 12:50:49,319 >>   Num examples = 270\n",
            "[INFO|trainer.py:2421] 2022-05-06 12:50:49,319 >>   Batch size = 8\n",
            "100% 34/34 [00:13<00:00,  2.50it/s]/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/06/2022 12:51:03 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 34/34 [00:13<00:00,  2.51it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =      0.966\n",
            "  eval_f1                 =     0.5933\n",
            "  eval_loss               =      0.123\n",
            "  eval_precision          =     0.5401\n",
            "  eval_recall             =     0.6581\n",
            "  eval_runtime            = 0:00:13.96\n",
            "  eval_samples            =        270\n",
            "  eval_samples_per_second =     19.341\n",
            "  eval_steps_per_second   =      2.436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##换了个模型 bert-wwm f1稍微高了点点 0.59"
      ],
      "metadata": {
        "id": "q8puEFDKbQ63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path hfl/chinese-roberta-wwm-ext \\\n",
        "  --dataset_name weibo_ner \\\n",
        "  --output_dir /content/roberta \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --fp16 \\\n",
        "  --do_eval \\\n",
        "  --save_strategy epoch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IJRjLtibf6s",
        "outputId": "6a511e06-c381-44d8-97e4-9ba76139b52b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 12:58:27 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/06/2022 12:58:27 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/roberta/runs/May06_12-58-26_edd37792f991,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=2.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/roberta,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/roberta,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 12:58:27 - WARNING - datasets.builder - Using custom data configuration default\n",
            "05/06/2022 12:58:27 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/weibo_ner/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:58:27 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/06/2022 12:58:27 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 12:58:27 - WARNING - datasets.builder - Reusing dataset weibo_ner_corpus (/root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a)\n",
            "05/06/2022 12:58:27 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "100% 3/3 [00:00<00:00, 646.44it/s]\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:58:28,697 >> loading configuration file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b64aa51c20341fe5461d0663677dd1527cc8fb71c482d06ee75406857d0ed53a.ec9dcc5b0fb354ff7e07c612e71b31e4e41d5ffafe36e4ac9b37959db8873460\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:58:28,698 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-roberta-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:58:30,223 >> loading configuration file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b64aa51c20341fe5461d0663677dd1527cc8fb71c482d06ee75406857d0ed53a.ec9dcc5b0fb354ff7e07c612e71b31e4e41d5ffafe36e4ac9b37959db8873460\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:58:30,224 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-roberta-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:58:34,787 >> loading file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/92a56e79ec6564fd501527ed88ca336637eb4bfeb28d10580c3bbdfb7889a032.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:58:34,787 >> loading file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e6278a884ec926a36ddf8d3cc3c598a65dd410c8c01be870468c4f2f71bee0d7.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:58:34,787 >> loading file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/87c7eedd995b4bae2c34df3baf2cbd5df5496bed675126427849c72e590f5574.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:58:34,787 >> loading file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/d521373fc7ac35f63d56cf303de74a202403dcf1aaa792cd01f653694be59563.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 12:58:34,787 >> loading file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/5dedf24c46ec573f8a27ddfa6e737869ec8df462a9a7682b35ded34301c5bdc8.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 12:58:35,545 >> loading configuration file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/b64aa51c20341fe5461d0663677dd1527cc8fb71c482d06ee75406857d0ed53a.ec9dcc5b0fb354ff7e07c612e71b31e4e41d5ffafe36e4ac9b37959db8873460\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 12:58:35,546 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-roberta-wwm-ext\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1772] 2022-05-06 12:58:36,356 >> loading weights file https://huggingface.co/hfl/chinese-roberta-wwm-ext/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ebc33cec9cd4890c20bd3b688fbf8e907167e0e2f209b801b3159123cd4630e4.d863eb12d1b0d00e5d41e9eb0d41914e4993c03e6de69e67bc10c79818f5fd4d\n",
            "[WARNING|modeling_utils.py:2049] 2022-05-06 12:58:38,139 >> Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2060] 2022-05-06 12:58:38,140 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "05/06/2022 12:58:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-590487abcc423a00.arrow\n",
            "05/06/2022 12:58:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-cdd250ca0f2b8d09.arrow\n",
            "[INFO|trainer.py:453] 2022-05-06 12:58:41,926 >> Using amp half precision backend\n",
            "[INFO|trainer.py:567] 2022-05-06 12:58:41,927 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1290] 2022-05-06 12:58:41,941 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2022-05-06 12:58:41,941 >>   Num examples = 1350\n",
            "[INFO|trainer.py:1292] 2022-05-06 12:58:41,942 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:1293] 2022-05-06 12:58:41,942 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2022-05-06 12:58:41,942 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2022-05-06 12:58:41,942 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2022-05-06 12:58:41,942 >>   Total optimization steps = 170\n",
            " 50% 85/170 [03:47<03:04,  2.17s/it][INFO|trainer.py:2166] 2022-05-06 13:02:29,428 >> Saving model checkpoint to /content/roberta/checkpoint-85\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:02:29,431 >> Configuration saved in /content/roberta/checkpoint-85/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:02:30,528 >> Model weights saved in /content/roberta/checkpoint-85/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:02:30,529 >> tokenizer config file saved in /content/roberta/checkpoint-85/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:02:30,529 >> Special tokens file saved in /content/roberta/checkpoint-85/special_tokens_map.json\n",
            "100% 170/170 [07:39<00:00,  2.31s/it][INFO|trainer.py:2166] 2022-05-06 13:06:21,297 >> Saving model checkpoint to /content/roberta/checkpoint-170\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:06:21,299 >> Configuration saved in /content/roberta/checkpoint-170/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:06:22,372 >> Model weights saved in /content/roberta/checkpoint-170/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:06:22,373 >> tokenizer config file saved in /content/roberta/checkpoint-170/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:06:22,373 >> Special tokens file saved in /content/roberta/checkpoint-170/special_tokens_map.json\n",
            "[INFO|trainer.py:1530] 2022-05-06 13:06:25,496 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 463.5543, 'train_samples_per_second': 5.825, 'train_steps_per_second': 0.367, 'train_loss': 0.28964805603027344, 'epoch': 2.0}\n",
            "100% 170/170 [07:43<00:00,  2.73s/it]\n",
            "[INFO|trainer.py:2166] 2022-05-06 13:06:25,499 >> Saving model checkpoint to /content/roberta\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:06:25,501 >> Configuration saved in /content/roberta/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:06:26,774 >> Model weights saved in /content/roberta/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:06:26,774 >> tokenizer config file saved in /content/roberta/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:06:26,775 >> Special tokens file saved in /content/roberta/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  train_loss               =     0.2896\n",
            "  train_runtime            = 0:07:43.55\n",
            "  train_samples            =       1350\n",
            "  train_samples_per_second =      5.825\n",
            "  train_steps_per_second   =      0.367\n",
            "05/06/2022 13:06:26 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:567] 2022-05-06 13:06:26,806 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2022-05-06 13:06:26,809 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2022-05-06 13:06:26,809 >>   Num examples = 270\n",
            "[INFO|trainer.py:2421] 2022-05-06 13:06:26,809 >>   Batch size = 8\n",
            "100% 34/34 [00:13<00:00,  2.45it/s]/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/06/2022 13:06:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 34/34 [00:13<00:00,  2.47it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =     0.9657\n",
            "  eval_f1                 =     0.6088\n",
            "  eval_loss               =     0.1166\n",
            "  eval_precision          =     0.5537\n",
            "  eval_recall             =     0.6761\n",
            "  eval_runtime            = 0:00:14.75\n",
            "  eval_samples            =        270\n",
            "  eval_samples_per_second =     18.295\n",
            "  eval_steps_per_second   =      2.304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#然后roberta-wwm又高了一些 0.6088"
      ],
      "metadata": {
        "id": "sOkEXuC8fVTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path peterchou/nezha-chinese-base \\\n",
        "  --dataset_name weibo_ner \\\n",
        "  --output_dir /content/nezha \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --fp16 \\\n",
        "  --do_eval \\\n",
        "  --save_strategy epoch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kmjRuZPcNlD",
        "outputId": "31348c92-de5a-40ee-f02a-b340d2c41379"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 13:13:31 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/06/2022 13:13:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/nezha/runs/May06_13-13-31_edd37792f991,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=2.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/nezha,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/nezha,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 13:13:32 - WARNING - datasets.builder - Using custom data configuration default\n",
            "05/06/2022 13:13:32 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/weibo_ner/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 13:13:32 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/06/2022 13:13:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 13:13:32 - WARNING - datasets.builder - Reusing dataset weibo_ner_corpus (/root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a)\n",
            "05/06/2022 13:13:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "100% 3/3 [00:00<00:00, 680.12it/s]\n",
            "[INFO|hub.py:583] 2022-05-06 13:13:33,413 >> https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxdmsokog\n",
            "Downloading: 100% 508/508 [00:00<00:00, 404kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:13:34,193 >> storing https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|hub.py:595] 2022-05-06 13:13:34,193 >> creating metadata file for /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:13:34,194 >> loading configuration file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:13:34,195 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"peterchou/nezha-chinese-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_position\": 64,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"use_relative_position\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:344] 2022-05-06 13:13:34,962 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:13:35,722 >> loading configuration file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:13:35,723 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"peterchou/nezha-chinese-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_position\": 64,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"use_relative_position\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 13:13:37,247 >> https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_vfyz739\n",
            "Downloading: 100% 107k/107k [00:00<00:00, 298kB/s] \n",
            "[INFO|hub.py:587] 2022-05-06 13:13:38,562 >> storing https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/ab8f331ba8d50bf2c8599c69bfa1e9fda064cfc267e947d040c112f0a1cdd13c.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:595] 2022-05-06 13:13:38,563 >> creating metadata file for /root/.cache/huggingface/transformers/ab8f331ba8d50bf2c8599c69bfa1e9fda064cfc267e947d040c112f0a1cdd13c.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:13:41,608 >> loading file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/ab8f331ba8d50bf2c8599c69bfa1e9fda064cfc267e947d040c112f0a1cdd13c.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:13:41,608 >> loading file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:13:41,608 >> loading file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:13:41,608 >> loading file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:13:41,608 >> loading file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:13:42,370 >> loading configuration file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:13:42,371 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"peterchou/nezha-chinese-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_position\": 64,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"use_relative_position\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:13:43,155 >> loading configuration file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f53df708e7e21c38059ccc43bb67fd1fc65321151abefe781857162f336bba01.f746c778cbf57aa7cb99febcbdbf59432c25c5704203d0c33db10f60368d989b\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:13:43,156 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"peterchou/nezha-chinese-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_position\": 64,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"use_relative_position\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 13:13:43,947 >> https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9e6scxqk\n",
            "Downloading: 100% 391M/391M [00:09<00:00, 43.4MB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:13:53,661 >> storing https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/65f80b466f786d8daa891b89e7b0c63b7aa8ef479c1b8175d0c552e6bda36a0f.20185119e61ea278fe4ee4a14805c7891e09a0e0b5800e9515342c122cd8172a\n",
            "[INFO|hub.py:595] 2022-05-06 13:13:53,661 >> creating metadata file for /root/.cache/huggingface/transformers/65f80b466f786d8daa891b89e7b0c63b7aa8ef479c1b8175d0c552e6bda36a0f.20185119e61ea278fe4ee4a14805c7891e09a0e0b5800e9515342c122cd8172a\n",
            "[INFO|modeling_utils.py:1772] 2022-05-06 13:13:53,661 >> loading weights file https://huggingface.co/peterchou/nezha-chinese-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/65f80b466f786d8daa891b89e7b0c63b7aa8ef479c1b8175d0c552e6bda36a0f.20185119e61ea278fe4ee4a14805c7891e09a0e0b5800e9515342c122cd8172a\n",
            "[WARNING|modeling_utils.py:2049] 2022-05-06 13:13:55,436 >> Some weights of the model checkpoint at peterchou/nezha-chinese-base were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2060] 2022-05-06 13:13:55,436 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at peterchou/nezha-chinese-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.embeddings.position_embeddings.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on train dataset:   0% 0/2 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:2340] 2022-05-06 13:13:55,574 >> Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "05/06/2022 13:13:55 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-e39a7406ad190877.arrow\n",
            "Running tokenizer on train dataset: 100% 2/2 [00:00<00:00,  2.65ba/s]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]05/06/2022 13:13:56 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-e8b2064168fe7f5b.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  7.37ba/s]\n",
            "[INFO|trainer.py:453] 2022-05-06 13:14:00,593 >> Using amp half precision backend\n",
            "[INFO|trainer.py:567] 2022-05-06 13:14:00,593 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1290] 2022-05-06 13:14:00,607 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2022-05-06 13:14:00,607 >>   Num examples = 1350\n",
            "[INFO|trainer.py:1292] 2022-05-06 13:14:00,608 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:1293] 2022-05-06 13:14:00,608 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2022-05-06 13:14:00,608 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2022-05-06 13:14:00,608 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2022-05-06 13:14:00,608 >>   Total optimization steps = 170\n",
            " 50% 85/170 [03:47<03:03,  2.16s/it][INFO|trainer.py:2166] 2022-05-06 13:17:47,832 >> Saving model checkpoint to /content/nezha/checkpoint-85\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:17:47,833 >> Configuration saved in /content/nezha/checkpoint-85/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:17:49,127 >> Model weights saved in /content/nezha/checkpoint-85/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:17:49,128 >> tokenizer config file saved in /content/nezha/checkpoint-85/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:17:49,128 >> Special tokens file saved in /content/nezha/checkpoint-85/special_tokens_map.json\n",
            "100% 170/170 [07:38<00:00,  2.31s/it][INFO|trainer.py:2166] 2022-05-06 13:21:39,282 >> Saving model checkpoint to /content/nezha/checkpoint-170\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:21:39,283 >> Configuration saved in /content/nezha/checkpoint-170/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:21:40,579 >> Model weights saved in /content/nezha/checkpoint-170/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:21:40,580 >> tokenizer config file saved in /content/nezha/checkpoint-170/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:21:40,580 >> Special tokens file saved in /content/nezha/checkpoint-170/special_tokens_map.json\n",
            "[INFO|trainer.py:1530] 2022-05-06 13:21:43,349 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 462.7413, 'train_samples_per_second': 5.835, 'train_steps_per_second': 0.367, 'train_loss': 0.5975800906910615, 'epoch': 2.0}\n",
            "100% 170/170 [07:42<00:00,  2.72s/it]\n",
            "[INFO|trainer.py:2166] 2022-05-06 13:21:43,351 >> Saving model checkpoint to /content/nezha\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:21:43,352 >> Configuration saved in /content/nezha/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:21:45,127 >> Model weights saved in /content/nezha/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:21:45,127 >> tokenizer config file saved in /content/nezha/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:21:45,127 >> Special tokens file saved in /content/nezha/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  train_loss               =     0.5976\n",
            "  train_runtime            = 0:07:42.74\n",
            "  train_samples            =       1350\n",
            "  train_samples_per_second =      5.835\n",
            "  train_steps_per_second   =      0.367\n",
            "05/06/2022 13:21:45 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:567] 2022-05-06 13:21:45,156 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2022-05-06 13:21:45,158 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2022-05-06 13:21:45,159 >>   Num examples = 270\n",
            "[INFO|trainer.py:2421] 2022-05-06 13:21:45,159 >>   Batch size = 8\n",
            "100% 34/34 [00:13<00:00,  2.47it/s]/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/06/2022 13:21:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 34/34 [00:13<00:00,  2.48it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =     0.9331\n",
            "  eval_f1                 =        0.0\n",
            "  eval_loss               =     0.4783\n",
            "  eval_precision          =        0.0\n",
            "  eval_recall             =        0.0\n",
            "  eval_runtime            = 0:00:14.10\n",
            "  eval_samples            =        270\n",
            "  eval_samples_per_second =     19.148\n",
            "  eval_steps_per_second   =      2.411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##果然崩了，hf上的nezha不知道哪里坏了，f1就是0了，使用nezha还是去github上那个longpatient哪里去用"
      ],
      "metadata": {
        "id": "w4saltwfilAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path hfl/chinese-macbert-base \\\n",
        "  --dataset_name weibo_ner \\\n",
        "  --output_dir /content/macbert \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --fp16 \\\n",
        "  --do_eval \\\n",
        "  --save_strategy epoch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdKL8Esmi-N8",
        "outputId": "63421cb5-c8cc-4401-8477-7d2475bb4032"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/06/2022 13:25:55 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "05/06/2022 13:25:55 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/macbert/runs/May06_13-25-55_edd37792f991,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=2.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=/content/macbert,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/macbert,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/06/2022 13:25:57 - WARNING - datasets.builder - Using custom data configuration default\n",
            "05/06/2022 13:25:57 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/weibo_ner/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 13:25:57 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "05/06/2022 13:25:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "05/06/2022 13:25:57 - WARNING - datasets.builder - Reusing dataset weibo_ner_corpus (/root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a)\n",
            "05/06/2022 13:25:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a\n",
            "100% 3/3 [00:00<00:00, 698.43it/s]\n",
            "[INFO|hub.py:583] 2022-05-06 13:25:58,214 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfytrgxzo\n",
            "Downloading: 100% 659/659 [00:00<00:00, 595kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:25:58,981 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/dfbc5cae1d1506a97fa3e0014d34afdd480ea8cce63302d8df982725a3e5b77a.ddc6437c26ae4493a14d93f62bb62ae67d1e46c0de74ff95524ad468354a19f7\n",
            "[INFO|hub.py:595] 2022-05-06 13:25:58,981 >> creating metadata file for /root/.cache/huggingface/transformers/dfbc5cae1d1506a97fa3e0014d34afdd480ea8cce63302d8df982725a3e5b77a.ddc6437c26ae4493a14d93f62bb62ae67d1e46c0de74ff95524ad468354a19f7\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:25:58,981 >> loading configuration file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dfbc5cae1d1506a97fa3e0014d34afdd480ea8cce63302d8df982725a3e5b77a.ddc6437c26ae4493a14d93f62bb62ae67d1e46c0de74ff95524ad468354a19f7\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:25:58,983 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-macbert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\",\n",
            "    \"14\": \"LABEL_14\",\n",
            "    \"15\": \"LABEL_15\",\n",
            "    \"16\": \"LABEL_16\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_14\": 14,\n",
            "    \"LABEL_15\": 15,\n",
            "    \"LABEL_16\": 16,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 13:25:59,741 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp57ytpdgh\n",
            "Downloading: 100% 19.0/19.0 [00:00<00:00, 16.2kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:26:00,506 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/28fd86fdb44cd30e24e9793d571ae709f73ce1aa12fb0d3e60e826d7c250a5a8.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:00,506 >> creating metadata file for /root/.cache/huggingface/transformers/28fd86fdb44cd30e24e9793d571ae709f73ce1aa12fb0d3e60e826d7c250a5a8.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:26:01,271 >> loading configuration file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dfbc5cae1d1506a97fa3e0014d34afdd480ea8cce63302d8df982725a3e5b77a.ddc6437c26ae4493a14d93f62bb62ae67d1e46c0de74ff95524ad468354a19f7\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:26:01,272 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-macbert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 13:26:02,798 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpqr0_n3c1\n",
            "Downloading: 100% 107k/107k [00:00<00:00, 199kB/s] \n",
            "[INFO|hub.py:587] 2022-05-06 13:26:04,111 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/229ce68be3619b81ba7498cc40301675d5d923a5c43f20e1db15d4b15f5c2006.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:04,111 >> creating metadata file for /root/.cache/huggingface/transformers/229ce68be3619b81ba7498cc40301675d5d923a5c43f20e1db15d4b15f5c2006.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|hub.py:583] 2022-05-06 13:26:04,876 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfxa8cr6r\n",
            "Downloading: 100% 263k/263k [00:00<00:00, 366kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:26:06,382 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/9dff099b9b46efd82fbc99787839c808ef5a7aa3dde3ed8fe0bfd8416b81e627.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:06,382 >> creating metadata file for /root/.cache/huggingface/transformers/9dff099b9b46efd82fbc99787839c808ef5a7aa3dde3ed8fe0bfd8416b81e627.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|hub.py:583] 2022-05-06 13:26:07,145 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpj71c5upx\n",
            "Downloading: 100% 2.00/2.00 [00:00<00:00, 1.70kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:26:07,908 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/6ee5a7f5e3aa2ba5afa7127d6be5c3451dbaf5d467557686094617bdf2beab74.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:07,908 >> creating metadata file for /root/.cache/huggingface/transformers/6ee5a7f5e3aa2ba5afa7127d6be5c3451dbaf5d467557686094617bdf2beab74.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|hub.py:583] 2022-05-06 13:26:08,670 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp062y8rh2\n",
            "Downloading: 100% 112/112 [00:00<00:00, 92.6kB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:26:09,433 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/9f382d012cf0761684535742ec8cf1096e0be52359ee0389a418eaada1265367.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:09,434 >> creating metadata file for /root/.cache/huggingface/transformers/9f382d012cf0761684535742ec8cf1096e0be52359ee0389a418eaada1265367.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:26:10,193 >> loading file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/229ce68be3619b81ba7498cc40301675d5d923a5c43f20e1db15d4b15f5c2006.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:26:10,193 >> loading file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/9dff099b9b46efd82fbc99787839c808ef5a7aa3dde3ed8fe0bfd8416b81e627.660ed5c7513bf13d4607410502a84e0de517eb889ff8c401068a1688868e1ccb\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:26:10,193 >> loading file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/6ee5a7f5e3aa2ba5afa7127d6be5c3451dbaf5d467557686094617bdf2beab74.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:26:10,193 >> loading file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/9f382d012cf0761684535742ec8cf1096e0be52359ee0389a418eaada1265367.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "[INFO|tokenization_utils_base.py:1778] 2022-05-06 13:26:10,193 >> loading file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/28fd86fdb44cd30e24e9793d571ae709f73ce1aa12fb0d3e60e826d7c250a5a8.d23f50bbddc3fb34db5a76d47fa9bdd5d75bf4201ad2d49abbcca25629b3e562\n",
            "[INFO|configuration_utils.py:654] 2022-05-06 13:26:10,955 >> loading configuration file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dfbc5cae1d1506a97fa3e0014d34afdd480ea8cce63302d8df982725a3e5b77a.ddc6437c26ae4493a14d93f62bb62ae67d1e46c0de74ff95524ad468354a19f7\n",
            "[INFO|configuration_utils.py:690] 2022-05-06 13:26:10,956 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"hfl/chinese-macbert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "[INFO|hub.py:583] 2022-05-06 13:26:11,760 >> https://huggingface.co/hfl/chinese-macbert-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpeemfp_ks\n",
            "Downloading: 100% 393M/393M [00:10<00:00, 38.7MB/s]\n",
            "[INFO|hub.py:587] 2022-05-06 13:26:22,449 >> storing https://huggingface.co/hfl/chinese-macbert-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/f350d12c99d2a8d00f4299b8e292c2248422676424702a2c45a8a3d65646f738.749c1a543002a65141e104ba5e040263fd8eabc9d2dcfb537bf681345565ef45\n",
            "[INFO|hub.py:595] 2022-05-06 13:26:22,449 >> creating metadata file for /root/.cache/huggingface/transformers/f350d12c99d2a8d00f4299b8e292c2248422676424702a2c45a8a3d65646f738.749c1a543002a65141e104ba5e040263fd8eabc9d2dcfb537bf681345565ef45\n",
            "[INFO|modeling_utils.py:1772] 2022-05-06 13:26:22,450 >> loading weights file https://huggingface.co/hfl/chinese-macbert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f350d12c99d2a8d00f4299b8e292c2248422676424702a2c45a8a3d65646f738.749c1a543002a65141e104ba5e040263fd8eabc9d2dcfb537bf681345565ef45\n",
            "[WARNING|modeling_utils.py:2049] 2022-05-06 13:26:24,222 >> Some weights of the model checkpoint at hfl/chinese-macbert-base were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2060] 2022-05-06 13:26:24,222 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on train dataset:   0% 0/2 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:2340] 2022-05-06 13:26:24,362 >> Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "05/06/2022 13:26:24 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-a5c7531b3dc7af70.arrow\n",
            "Running tokenizer on train dataset: 100% 2/2 [00:00<00:00,  2.67ba/s]\n",
            "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]05/06/2022 13:26:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/weibo_ner_corpus/default/1.0.0/4a93f6e0f1024e5dd7a7ea6c604e5a5455bb8ff6cf87ff76dcd057fe99a0f62a/cache-ced741bb06a36876.arrow\n",
            "Running tokenizer on validation dataset: 100% 1/1 [00:00<00:00,  7.59ba/s]\n",
            "[INFO|trainer.py:453] 2022-05-06 13:26:29,259 >> Using amp half precision backend\n",
            "[INFO|trainer.py:567] 2022-05-06 13:26:29,260 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1290] 2022-05-06 13:26:29,274 >> ***** Running training *****\n",
            "[INFO|trainer.py:1291] 2022-05-06 13:26:29,274 >>   Num examples = 1350\n",
            "[INFO|trainer.py:1292] 2022-05-06 13:26:29,274 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:1293] 2022-05-06 13:26:29,274 >>   Instantaneous batch size per device = 16\n",
            "[INFO|trainer.py:1294] 2022-05-06 13:26:29,275 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1295] 2022-05-06 13:26:29,275 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1296] 2022-05-06 13:26:29,275 >>   Total optimization steps = 170\n",
            " 50% 85/170 [03:47<03:04,  2.16s/it][INFO|trainer.py:2166] 2022-05-06 13:30:16,851 >> Saving model checkpoint to /content/macbert/checkpoint-85\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:30:16,852 >> Configuration saved in /content/macbert/checkpoint-85/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:30:17,990 >> Model weights saved in /content/macbert/checkpoint-85/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:30:17,996 >> tokenizer config file saved in /content/macbert/checkpoint-85/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:30:17,997 >> Special tokens file saved in /content/macbert/checkpoint-85/special_tokens_map.json\n",
            "100% 170/170 [07:38<00:00,  2.31s/it][INFO|trainer.py:2166] 2022-05-06 13:34:07,979 >> Saving model checkpoint to /content/macbert/checkpoint-170\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:34:07,980 >> Configuration saved in /content/macbert/checkpoint-170/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:34:09,022 >> Model weights saved in /content/macbert/checkpoint-170/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:34:09,023 >> tokenizer config file saved in /content/macbert/checkpoint-170/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:34:09,023 >> Special tokens file saved in /content/macbert/checkpoint-170/special_tokens_map.json\n",
            "[INFO|trainer.py:1530] 2022-05-06 13:34:11,968 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 462.6933, 'train_samples_per_second': 5.835, 'train_steps_per_second': 0.367, 'train_loss': 0.31609207602108225, 'epoch': 2.0}\n",
            "100% 170/170 [07:42<00:00,  2.72s/it]\n",
            "[INFO|trainer.py:2166] 2022-05-06 13:34:11,971 >> Saving model checkpoint to /content/macbert\n",
            "[INFO|configuration_utils.py:441] 2022-05-06 13:34:11,972 >> Configuration saved in /content/macbert/config.json\n",
            "[INFO|modeling_utils.py:1378] 2022-05-06 13:34:13,792 >> Model weights saved in /content/macbert/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2086] 2022-05-06 13:34:13,793 >> tokenizer config file saved in /content/macbert/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2092] 2022-05-06 13:34:13,793 >> Special tokens file saved in /content/macbert/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  train_loss               =     0.3161\n",
            "  train_runtime            = 0:07:42.69\n",
            "  train_samples            =       1350\n",
            "  train_samples_per_second =      5.835\n",
            "  train_steps_per_second   =      0.367\n",
            "05/06/2022 13:34:13 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:567] 2022-05-06 13:34:13,823 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2416] 2022-05-06 13:34:13,825 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2418] 2022-05-06 13:34:13,825 >>   Num examples = 270\n",
            "[INFO|trainer.py:2421] 2022-05-06 13:34:13,826 >>   Batch size = 8\n",
            "100% 34/34 [00:13<00:00,  2.45it/s]/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/06/2022 13:34:28 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n",
            "100% 34/34 [00:13<00:00,  2.46it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        2.0\n",
            "  eval_accuracy           =     0.9642\n",
            "  eval_f1                 =     0.5494\n",
            "  eval_loss               =     0.1312\n",
            "  eval_precision          =     0.4969\n",
            "  eval_recall             =     0.6144\n",
            "  eval_runtime            = 0:00:14.20\n",
            "  eval_samples            =        270\n",
            "  eval_samples_per_second =     19.011\n",
            "  eval_steps_per_second   =      2.394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner.py \\\n",
        "  --model_name_or_path bert-base-chinese \\\n",
        "  --train_file train.csv \\\n",
        "  --validation_file valid.csv \\\n",
        "  --test_file test.csv \\\n",
        "  --output_dir /content/roberta_ \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LFHxdxUEuIm",
        "outputId": "bc3b5fd0-eb02-45a3-da1b-2d348e2c5d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"run_ner.py\", line 51, in <module>\n",
            "    check_min_version(\"4.18.0.dev0\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/utils/__init__.py\", line 35, in check_min_version\n",
            "    \"Check out https://huggingface.co/transformers/examples.html for the examples corresponding to other \"\n",
            "ImportError: This example requires a source install from HuggingFace Transformers (see `https://huggingface.co/transformers/installation.html#installing-from-source`), but the version found is 4.17.0.\n",
            "Check out https://huggingface.co/transformers/examples.html for the examples corresponding to other versions of HuggingFace Transformers.\n"
          ]
        }
      ]
    }
  ]
}