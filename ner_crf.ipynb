{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_crf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP66qSQA+b4pwa9yO7jynFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/NER/blob/main/ner_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#使用CRF实现NER\n",
        "\n",
        "*     数据集 CONLL\n",
        "*     特征工程 bi-gram +pos\n",
        "*     模型  CRF (sklearn_crfsuite)\n"
      ],
      "metadata": {
        "id": "X-cU9MYu_y6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#下载数据\n",
        "!mkdir data\n",
        "!wget https://data.deepai.org/conll2003.zip\n",
        "!unzip -d data conll2003.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZLmf77QTUXV",
        "outputId": "d9b787a8-b476-4abe-f475-0da536f019f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2022-03-06 08:48:17--  https://data.deepai.org/conll2003.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 138.201.36.183\n",
            "Connecting to data.deepai.org (data.deepai.org)|138.201.36.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 982975 (960K) [application/x-zip-compressed]\n",
            "Saving to: ‘conll2003.zip.1’\n",
            "\n",
            "conll2003.zip.1     100%[===================>] 959.94K  2.09MB/s    in 0.4s    \n",
            "\n",
            "2022-03-06 08:48:17 (2.09 MB/s) - ‘conll2003.zip.1’ saved [982975/982975]\n",
            "\n",
            "Archive:  conll2003.zip\n",
            "replace data/metadata? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/train.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/valid.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR6pCGAnAcZE",
        "outputId": "a772f6f1-e988-44b3-9dd4-9d0b652ff66a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.63.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_hN6ZgbS_tHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6faf92-dcce-4122-f817-9549585d5212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "#导入必要的包\n",
        "import nltk\n",
        "import sklearn\n",
        "#下载nltk词性标注和分词的工具\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "from nltk.tag import pos_tag\n",
        "from sklearn_crfsuite import CRF ,metrics\n",
        "from sklearn.metrics import make_scorer,confusion_matrix\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import f1_score,classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#查看数据形式\n",
        "!head -n 20 data/train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTIrfwzXVt2D",
        "outputId": "acb62c47-52d3-4177-ef67-c842465164d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP B-NP B-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP B-NP B-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT B-NP O\n",
            "European NNP I-NP B-ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "数据前两行为标题，一共四列，分别为\n",
        "*    token\n",
        "*    pos\n",
        "*    ——\n",
        "*    entity Labels\n",
        "每列中间使用空格分隔，每句话中间使用空行进行分割"
      ],
      "metadata": {
        "id": "BqevQY8pV1eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#导入数据"
      ],
      "metadata": {
        "id": "CZ7Hq8EKUMGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load__data_conll(file_path):\n",
        "    myoutput,words,tags = [],[],[]\n",
        "    with open(file_path,'r',encoding='utf-8') as f:\n",
        "      content=f.readlines()\n",
        "    for line in content[2:]:\n",
        "        line = line.strip()\n",
        "        if \" \" not in line:\n",
        "            #Sentence ended.\n",
        "            myoutput.append([words,tags])\n",
        "            words,tags = [],[]\n",
        "        else:\n",
        "            word,_,_,tag = line.split(\" \")\n",
        "            words.append(word)\n",
        "            tags.append(tag)\n",
        "    return myoutput"
      ],
      "metadata": {
        "id": "TGLaCt6CUOvu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#特征工程\n",
        "这里使用bi-gram作为特征，然后使用nlp.pos_tag词性作为辅助特征。"
      ],
      "metadata": {
        "id": "j68ZLQDGWsNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent2feats(sentence):\n",
        "    feats = []\n",
        "    sen_tags = pos_tag(sentence) #This format is specific to this POS tagger!\n",
        "    for i in range(0,len(sentence)):\n",
        "        word = sentence[i]\n",
        "        wordfeats = {}\n",
        "       #word features: word, prev 2 words, next 2 words in the sentence.\n",
        "        wordfeats['word'] = word\n",
        "        if i == 0:\n",
        "            wordfeats[\"prevWord\"] = wordfeats[\"prevSecondWord\"] = \"<S>\"\n",
        "        elif i==1:\n",
        "            wordfeats[\"prevWord\"] = sentence[0]\n",
        "            wordfeats[\"prevSecondWord\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"prevWord\"] = sentence[i-1]\n",
        "            wordfeats[\"prevSecondWord\"] = sentence[i-2]\n",
        "        #next two words as features\n",
        "        if i == len(sentence)-2:\n",
        "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
        "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
        "        elif i==len(sentence)-1:\n",
        "            wordfeats[\"nextWord\"] = \"</S>\"\n",
        "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
        "            wordfeats[\"nextNextWord\"] = sentence[i+2]\n",
        "        \n",
        "        #POS tag features: current tag, previous and next 2 tags.\n",
        "        wordfeats['tag'] = sen_tags[i][1]\n",
        "        if i == 0:\n",
        "            wordfeats[\"prevTag\"] = wordfeats[\"prevSecondTag\"] = \"<S>\"\n",
        "        elif i == 1:\n",
        "            wordfeats[\"prevTag\"] = sen_tags[0][1]\n",
        "            wordfeats[\"prevSecondTag\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"prevTag\"] = sen_tags[i - 1][1]\n",
        "\n",
        "            wordfeats[\"prevSecondTag\"] = sen_tags[i - 2][1]\n",
        "            # next two words as features\n",
        "        if i == len(sentence) - 2:\n",
        "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
        "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
        "        elif i == len(sentence) - 1:\n",
        "            wordfeats[\"nextTag\"] = \"</S>\"\n",
        "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
        "            wordfeats[\"nextNextTag\"] = sen_tags[i + 2][1]\n",
        "        #That is it! You can add whatever you want!\n",
        "        feats.append(wordfeats)\n",
        "    return feats"
      ],
      "metadata": {
        "id": "2phE7P_tXBh-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 提取特征"
      ],
      "metadata": {
        "id": "YiW0SpA1XU6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#计算并显示困惑矩阵\n",
        "\n",
        "def get_confusion_matrix(y_true,y_pred,labels):\n",
        "    trues,preds = [], []\n",
        "    for yseq_true, yseq_pred in zip(y_true, y_pred):\n",
        "        trues.extend(yseq_true)\n",
        "        preds.extend(yseq_pred)\n",
        "    print_cm(confusion_matrix(trues,preds),labels)\n",
        "\n",
        "def print_cm(cm, labels):\n",
        "    print(\"\\n\")\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        sum = 0\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.0f\".format(columnwidth) % cm[i, j]\n",
        "            sum =  sum + int(cell)\n",
        "            print(cell, end=\" \")\n",
        "        print(sum) #Prints the total number of instances per cat at the end."
      ],
      "metadata": {
        "id": "qWa8UGzYaFK3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feats_conll(conll_data):\n",
        "    feats = []\n",
        "    labels = []\n",
        "    for sentence in conll_data:\n",
        "        feats.append(sent2feats(sentence[0]))\n",
        "        labels.append(sentence[1])\n",
        "    return feats, labels"
      ],
      "metadata": {
        "id": "34-1dYyqXUMG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#训练模型"
      ],
      "metadata": {
        "id": "8jbx11gBXcFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#训练一个序列模型\n",
        "def train_seq(X_train,Y_train,X_dev,Y_dev):\n",
        "  crf=CRF(algorithm='lbfgs',c1=0.1,c2=10,max_iterations=50,all_possible_states=True)\n",
        "  crf.fit(X_train,Y_train)\n",
        "  labels=list(crf.classes_)\n",
        "\n",
        "  #testing\n",
        "  y_pred=crf.predict(X_dev)\n",
        "  sorted_labels=sorted(labels,key=lambda name:(name[1:],name[0]))\n",
        "  print('sorted labels :',sorted_labels)\n",
        "  print(metrics.flat_f1_score(Y_dev,y_pred,average='weighted',labels=labels))\n",
        "  print(metrics.sequence_accuracy_score(Y_dev, y_pred))\n",
        "  #计算每一类的标签的p,r,f值，用于标签类别不平均的情况\n",
        "  y_true_sum=[]\n",
        "  y_pred_sum=[]\n",
        "  for i in Y_dev:\n",
        "    y_true_sum+=i\n",
        "  for i in y_pred:\n",
        "    y_pred_sum+=i\n",
        "  print(sklearn.metrics.classification_report(y_true_sum, y_pred_sum,labels=sorted_labels))\n",
        "  get_confusion_matrix(Y_dev, y_pred,labels=sorted_labels)\n",
        "\n",
        "  return crf"
      ],
      "metadata": {
        "id": "d8CibL0TXbe1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#在main中调用我们的函数"
      ],
      "metadata": {
        "id": "CXdrnWNaaRtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \n",
        "    \n",
        "    train_path = 'data/train.txt'\n",
        "    test_path = 'data/test.txt'\n",
        "        \n",
        "    conll_train = load__data_conll(train_path)\n",
        "    conll_dev = load__data_conll(test_path)\n",
        "    \n",
        "    print(\"Training a Sequence classification model with CRF\")\n",
        "    feats, labels = get_feats_conll(conll_train)\n",
        "    devfeats, devlabels = get_feats_conll(conll_dev)\n",
        "    model=train_seq(feats, labels, devfeats, devlabels)\n",
        "    print(\"Done with sequence model\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHvifmA5aXNP",
        "outputId": "5c50cabc-5d10-438b-fb55-f9e69abe540e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training a Sequence classification model with CRF\n",
            "sorted labels : ['O', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER']\n",
            "0.9291277569768975\n",
            "0.5929948411620961\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.97      0.98      0.98     38553\n",
            "       B-LOC       0.72      0.77      0.74      1668\n",
            "       I-LOC       0.80      0.49      0.61       257\n",
            "      B-MISC       0.70      0.36      0.48       702\n",
            "      I-MISC       0.67      0.52      0.58       216\n",
            "       B-ORG       0.68      0.57      0.62      1661\n",
            "       I-ORG       0.56      0.71      0.62       835\n",
            "       B-PER       0.77      0.79      0.78      1617\n",
            "       I-PER       0.82      0.90      0.86      1156\n",
            "\n",
            "    accuracy                           0.93     46665\n",
            "   macro avg       0.74      0.68      0.70     46665\n",
            "weighted avg       0.93      0.93      0.93     46665\n",
            "\n",
            "\n",
            "\n",
            "                O  B-LOC  I-LOC B-MISC I-MISC  B-ORG  I-ORG  B-PER  I-PER \n",
            "         O   1286     36     91     94      1      1     13      4    142 1668\n",
            "     B-LOC     42    255     55     22      1      2     14      3    308 702\n",
            "     I-LOC    224     44    939    160      0      2     24      5    263 1661\n",
            "    B-MISC    114      3     74   1273      0      2     42     12     97 1617\n",
            "    I-MISC      6      0      0      0    127      5     53     34     32 257\n",
            "     B-ORG      1      4      2      0      3    112     31     11     52 216\n",
            "     I-ORG     13      2     20      8     16     11    593     96     76 835\n",
            "     B-PER      0      0      2      0      6      2     74   1045     27 1156\n",
            "     I-PER    107     21    188     88      5     30    223     65  37826 38553\n",
            "Done with sequence model\n"
          ]
        }
      ]
    }
  ]
}