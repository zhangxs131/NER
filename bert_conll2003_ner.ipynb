{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_conll_ner_with_pytorch_pretrained_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkyOcsVd0N1n0+M9bAjmUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/NER/blob/main/bert_conll2003_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NER using Bert\n",
        "\n",
        "本文使用pytorch-pretrained-bert训练一个NER模型,数据集使用了conll2003,可以从 https://deepai.org/dataset/conll-2003-english\n",
        "下载\n",
        "\n",
        "模型就是bert-base-uncased\n",
        "\n",
        "经过本文复习了一些训练验证的基本流程，对NER预训练模型数据处理流程。\n",
        "\n",
        "本文改进，对token和label对齐只是简单对齐，由于tokenizer不同，使得分词后的标签数目，于label的标签无法对齐，这也是NER的一个重要问题。模型使用pytorch-pretrained-bert，这个库已经不更新了，还是应该使用huggingfacae的transformers进行更方便，快捷。"
      ],
      "metadata": {
        "id": "5lkbfJ32rh3R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvx20Aw9PEit",
        "outputId": "ee2235fa-3444-42a3-f3ee-677d1448fc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert==0.4.0\n",
            "  Downloading pytorch_pretrained_bert-0.4.0-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.4.0) (1.21.5)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.18-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert==0.4.0) (3.10.0.2)\n",
            "Collecting botocore<1.25.0,>=1.24.18\n",
            "  Downloading botocore-1.24.18-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 42.6 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.18->boto3->pytorch-pretrained-bert==0.4.0) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.18->boto3->pytorch-pretrained-bert==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.4.0) (2021.10.8)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.18 botocore-1.24.18 jmespath-0.10.0 pytorch-pretrained-bert-0.4.0 s3transfer-0.5.2 urllib3-1.25.11\n",
            "Collecting seqeval==0.0.12\n",
            "  Downloading seqeval-0.0.12.tar.gz (21 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12) (1.21.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12) (2.8.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7435 sha256=f9aef1093089ef4ea37d9716c96d5e899b26fc2ce4a3ed45ccb6f19fbee7cfb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ]
        }
      ],
      "source": [
        "#安装相关包\n",
        "!pip install pytorch-pretrained-bert==0.4.0\n",
        "!pip install seqeval==0.0.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset ,DataLoader,Dataset,RandomSampler,SequentialSampler\n",
        "from pytorch_pretrained_bert import BertTokenizer,BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification \n",
        "\n",
        "#帮助处理数据的包\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#计算F1值\n",
        "from seqeval.metrics import f1_score"
      ],
      "metadata": {
        "id": "_pilB2SFQOCc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#上传数据文件 conll2003\n",
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "wPfFX0K4RdgE",
        "outputId": "fb8b1643-384f-498a-feab-f8fe16e2a77e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-abe503af-a36c-40c7-a73d-e5f89159992e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-abe503af-a36c-40c7-a73d-e5f89159992e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving conll2003.zip to conll2003.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip conll2003.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpeOXO55R5Qi",
        "outputId": "1da6e860-ada0-4652-ad0c-5d4c34df97c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  conll2003.zip\n",
            "  inflating: metadata                \n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: valid.txt               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#数据处理\n",
        "\n",
        "这里只需要data中 words和NERtags两列\n",
        "\n",
        "特征选择word和word_pos_of_speech 使用"
      ],
      "metadata": {
        "id": "w_OyLsA1SETa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the training/testing data. \n",
        "input: conll format data, but with only 2 tab separated colums - words and NEtags.\n",
        "output: A list where each item is 2 lists.  sentence as a list of tokens, NER tags as a list for each token.\n",
        "\"\"\"\n",
        "#functions for preparing the data in the *.txt files\n",
        "def load__data_conll(file_path):\n",
        "    myoutput,words,poses,tags = [],[],[],[]\n",
        "    fh = open(file_path)\n",
        "    for line in fh:\n",
        "        line = line.strip()\n",
        "        if \" \" not in line:\n",
        "            #Sentence ended.\n",
        "            myoutput.append([words,poses,tags])\n",
        "            words,poses,tags =[],[],[]\n",
        "        else:\n",
        "            word,pos,_, tag = line.split(\" \")\n",
        "            words.append(word)\n",
        "            poses.append(pos)\n",
        "            tags.append(tag)\n",
        "    fh.close()\n",
        "    return myoutput\n"
      ],
      "metadata": {
        "id": "5Ip58bLqTkbM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'train.txt'\n",
        "test_path = 'test.txt' \n",
        "\n",
        "conll_train = load__data_conll(train_path)\n",
        "conll_test = load__data_conll(test_path)  \n"
      ],
      "metadata": {
        "id": "O0MsBv4FSB7Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#预处理句子，将一些特殊符号进行转换，\n",
        "import re\n",
        "def untokenize(words):\n",
        "    \"\"\"\n",
        "    Untokenizing a text undoes the tokenizing operation, restoring\n",
        "    punctuation and spaces to the places that people expect them to be.\n",
        "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
        "    except for line breaks.\n",
        "    \"\"\"\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    return step6.strip()\n",
        "\n",
        "print(untokenize(conll_test[3][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y--Kflm1TxRU",
        "outputId": "28305131-1ec4-48d8-c019-ae71b09792ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AL-AIN, United Arab Emirates 1996-12-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets convert them to dataframs for easier handling\n",
        "df_train = pd.DataFrame(conll_train,columns=[\"sentence\",\"pos\",\"labels\"])\n",
        "df_test = pd.DataFrame(conll_test,columns=[\"sentence\",\"pos\",\"labels\"])"
      ],
      "metadata": {
        "id": "_Gq84ipMWYeD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#整合所有数据\n",
        "\n",
        "sentences = list(df_train['sentence'])+list(df_test['sentence'])\n",
        "sentences = [untokenize(sent) for sent in sentences]\n",
        "\n",
        "labels = list(df_train['labels'])+list(df_test['labels']) \n",
        "print(len(sentences),len(labels))"
      ],
      "metadata": {
        "id": "PqLIcIQEWgHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用tokenizer处理数据\n",
        "\n",
        "现在我们得到word和labels，使用berttokenizer处理数据\n"
      ],
      "metadata": {
        "id": "ueMhPQ7NXMkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_gpu=torch.cuda.device_count()\n",
        "print('num of gpu is ',n_gpu)\n",
        "\n",
        "#设置超参数\n",
        "\n",
        "max_length=75\n",
        "batch_size=32\n",
        "\n",
        "#不区分大小写的bert base tokenizer\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
        "tokenized_texts=list(map(lambda x:['[CLS]']+tokenizer.tokenize(x)+['[SEP]'],sentences))\n",
        "\n",
        "print(tokenized_texts[4])\n",
        "print(len(tokenized_texts[4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeEBWMW2XXLj",
        "outputId": "525c8bf9-393d-4a1d-b313-56780e6cda1b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of gpu is  1\n",
            "['[CLS]', 'the', 'european', 'commission', 'said', 'on', 'thursday', 'it', 'disagreed', 'with', 'german', 'advice', 'to', 'consumers', 'to', 'shu', '##n', 'british', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.', '[SEP]']\n",
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[4])\n",
        "print(len(labels[4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMI2vclzYfI3",
        "outputId": "0eac4395-a60e-408d-aaeb-2e9476b8557b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#标签进行数值化\n",
        "lab=[]\n",
        "for label in labels[:1000]:\n",
        "  lab=lab+label\n",
        "tag_vals=list(set(lab))\n",
        "tag2idx={t:i for i,t in enumerate(tag_vals)}\n",
        "tag2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf6I8ccQadzJ",
        "outputId": "8e282ebf-5917-437f-e3b5-26b150ecdcab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC': 6,\n",
              " 'B-MISC': 0,\n",
              " 'B-ORG': 1,\n",
              " 'B-PER': 4,\n",
              " 'I-LOC': 8,\n",
              " 'I-MISC': 5,\n",
              " 'I-ORG': 7,\n",
              " 'I-PER': 3,\n",
              " 'O': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#将input和label转为tensor，并进行padding和truncaiton\n",
        "\n",
        "input_ids=pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                        maxlen=max_length,dtype='long',truncating='post',padding=\"post\")\n",
        "\n",
        "tags=pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                   maxlen=max_length,value=tag2idx['O'],padding='post',\n",
        "                   dtype='long',truncating='post')\n",
        "\n",
        "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
      ],
      "metadata": {
        "id": "R_6nJg8Tbk4K"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#划分训练集和验证集\n",
        "\n",
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, random_state=2022, test_size=0.2)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,  random_state=2022, test_size=0.2)\n",
        "\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "metadata": {
        "id": "Pwuasm86ctvr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#创建dataloader\n",
        "\n",
        "train_data=TensorDataset(tr_inputs,tr_masks,tr_tags)\n",
        "valid_data=TensorDataset(val_inputs, val_masks, val_tags)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "F0yjXK_Fdeg4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#加载模型\n",
        "\n",
        "model=BertForTokenClassification.from_pretrained('bert-base-uncased',num_labels=len(tag_vals))\n",
        "\n",
        "full_finetuning=True\n",
        "\n",
        "if full_finetuning:\n",
        "  param_optimizer=list(model.named_parameters())\n",
        "  no_decay=['bias','gamma','beta']\n",
        "  optimizer_grouped_parameters=[\n",
        "    {'params':[p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay_rate':0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay_rate': 0.0}\n",
        "  ]\n",
        "else:\n",
        "  param_optimizer = list(model.classifier.named_parameters()) \n",
        "  optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "metadata": {
        "id": "tM9ngwQBd4sx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算accuracy \n",
        "def flat_accuracy(pred,labels):\n",
        "  pred_flat =np.argmax(pred,axis=2).flatten()\n",
        "  label_flat=labels.flatten()\n",
        "  return np.sum(pred_flat==label_flat) /len(label_flat)\n",
        "  "
      ],
      "metadata": {
        "id": "6InpeDKvfk8b"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train 训练模型"
      ],
      "metadata": {
        "id": "VXnLFfcqgF3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=2\n",
        "max_grad_norm=1.0\n",
        "\n",
        "step=0\n",
        "train_loss_set=[]\n",
        "model.cuda()\n",
        "for i in range(epochs):\n",
        "  print('Epoch {}________________'.format(i+1))\n",
        "  model.train()\n",
        "  tr_loss=0\n",
        "  tr_examples,tr_steps=0,0\n",
        "\n",
        "  for batch in tqdm(train_dataloader):\n",
        "    batch=tuple(t.to(device) for t in batch)\n",
        "    b_input_ids,b_input_mask,b_labels=batch\n",
        "\n",
        "    loss=model(b_input_ids,attention_mask=b_input_mask,token_type_ids=None,labels=b_labels)\n",
        "    train_loss_set.append(loss)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    tr_loss+=loss.item()\n",
        "    tr_examples+=b_input_ids.size(0)\n",
        "    tr_steps+=1\n",
        "    step+=1\n",
        "    if step%20==0:\n",
        "      print('Epoch {} ,Step {} Train Loss {}'.format(i+1,step,loss.item()))\n",
        "\n",
        "    # gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "\n",
        "    #更新\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "  print('Epoch {} ,Train Loss {} '.format(i+1,tr_loss/tr_steps))\n",
        "\n",
        "  #验证集\n",
        "  model.eval()\n",
        "  eval_loss,eval_accuracy=0,0\n",
        "  eval_example,eval_steps=0,0\n",
        "  prediction,true_labels=[],[]\n",
        "\n",
        "  for batch in valid_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits = model(b_input_ids, token_type_ids=None,attention_mask=b_input_mask)\n",
        "\n",
        "      logits_ids=logits.detach().cpu().numpy()\n",
        "      label_ids=b_labels.to('cpu').numpy()\n",
        "      prediction.extend([list(p) for p in np.argmax(logits_ids, axis=2)])\n",
        "      true_labels.append(label_ids)\n",
        "\n",
        "      tmp_eval_accuracy = flat_accuracy(logits_ids, label_ids)\n",
        "      eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "      eval_example += b_input_ids.size(0)\n",
        "      eval_steps += 1\n",
        "  print(\"Epoch {} Validation Accuracy: {}\".format(i+1,eval_accuracy/eval_steps))\n",
        "\n",
        "  #F1值计算\n",
        "  pred_tags = [tag_vals[p_i] for p in prediction for p_i in p]\n",
        "  valid_tags = [tag_vals[l_ii] for l in true_labels  for l_i in l for l_ii in l_i]\n",
        "  print(\"Epoch {} F1-Score: {}\".format(i+1,f1_score(pred_tags, valid_tags)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iLFrwNYgJM0",
        "outputId": "48b4d5fd-8d60-4205-8315-537832f0214d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 F1-Score: 0.7518685983205684\n",
            "Epoch 2 F1-Score: 0.7518685983205684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#可视化损失\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.ylim(0,0.25)\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lXC8GuJvkzv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#验证集\n",
        "model.eval()\n",
        "eval_loss,eval_accuracy=0,0\n",
        "eval_example,eval_steps=0,0\n",
        "prediction,true_labels=[],[]\n",
        "\n",
        "for batch in valid_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(b_input_ids, token_type_ids=None,attention_mask=b_input_mask)\n",
        "\n",
        "    logits_ids=logits.detach().cpu().numpy()\n",
        "    label_ids=b_labels.to('cpu').numpy()\n",
        "    prediction.extend([list(p) for p in np.argmax(logits_ids, axis=2)])\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits_ids, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    eval_example += b_input_ids.size(0)\n",
        "    eval_steps += 1\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/eval_steps))\n",
        "\n",
        "#F1值计算\n",
        "pred_tags = [tag_vals[p_i] for p in prediction for p_i in p]\n",
        "valid_tags = [tag_vals[l_ii] for l in true_labels  for l_i in l for l_ii in l_i]\n",
        "print(\"F1-Score: {}\".format(f1_score(pred_tags,valid_tags)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxpozaX6l8vg",
        "outputId": "ce7a21b3-cb1a-4643-a7f0-d43d011ccddf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.989743589743589\n",
            "F1-Score: 0.7518685983205684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#保存模型\n",
        "torch.save(model.state_dict(),'bert_for_conll.pth')\n",
        "torch.save(optimizer.state_dict(),'optimizer_for_conll.pth')"
      ],
      "metadata": {
        "id": "tyK9zLfKmA74"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}